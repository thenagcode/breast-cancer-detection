ğŸ§¬ Breast Cancer Classification â€“ PyTorch & TensorFlow





ğŸ“– Overview
This project is a side-by-side implementation of a Breast Cancer Classification model using two leading deep learning frameworks â€” PyTorch and TensorFlow/Keras.
The idea was to learn by doing and compare both frameworks in terms of:

Syntax & workflow

Training loop control vs. abstraction

Performance and ease of implementation

The dataset used is the Breast Cancer Wisconsin Dataset, a classic binary classification dataset available in scikit-learn.

ğŸ¯ Objectives
Learn how to load, preprocess, and split datasets for deep learning.

Understand how binary classification works in neural networks.

Compare manual training loops in PyTorch vs high-level APIs in TensorFlow/Keras.

Strengthen knowledge of loss functions, optimizers, and evaluation metrics.

Build a project that can be showcased in a portfolio.

ğŸ› ï¸ Technologies & Libraries
Common:
Python 3.x

numpy, pandas â€“ Data manipulation

scikit-learn â€“ Dataset loading, train-test splitting, standardization

matplotlib â€“ Visualization

PyTorch Implementation (test_torch.ipynb):
torch â€“ Core deep learning library

torch.nn â€“ Neural network layers

torch.optim â€“ Optimizers (Adam)

Manual training loop for full control

TensorFlow Implementation (test_tf.ipynb):
tensorflow / keras â€“ Model building and training

Sequential API for rapid prototyping

Built-in .fit() training loop

ğŸ“Š Dataset Information
Dataset Name: Breast Cancer Wisconsin Dataset
Samples: 569
Features: 30 numerical features (mean radius, texture, perimeter, etc.)
Target:

0 â†’ Malignant

1 â†’ Benign

ğŸ“Œ Dataset Feature Breakdown

ğŸ§  Model Architecture
PyTorch & TensorFlow Shared Design
Input Layer: 30 neurons (one for each feature)

Hidden Layer(s): Dense layer(s) with ReLU activation

Output Layer: Single neuron with Sigmoid activation for binary classification

Diagram:

ğŸ“‚ Project Structure
bash
Copy
Edit
ğŸ“¦ Breast-Cancer-Classification
 â”£ ğŸ“œ test_torch.ipynb     # PyTorch version
 â”£ ğŸ“œ test_tf.ipynb        # TensorFlow/Keras version
 â”£ ğŸ“œ README.md            # Project documentation
 â”£ ğŸ–¼ dataset_breakdown.png
 â”£ ğŸ–¼ nn_architecture.png
 â”£ ğŸ–¼ training_flow.png
ğŸš€ Getting Started
1ï¸âƒ£ Install dependencies
bash
Copy
Edit
pip install torch tensorflow scikit-learn pandas matplotlib
2ï¸âƒ£ Run Jupyter Notebook
bash
Copy
Edit
jupyter notebook test_torch.ipynb
jupyter notebook test_tf.ipynb
ğŸ§  Learning Journey
What I Learned
Data Preprocessing: The importance of scaling data before training.

Model Architecture:

Input layer â†’ Hidden layer(s) with ReLU â†’ Output layer with Sigmoid.

Training Loops:

PyTorch: Fully manual loop with forward pass, loss calculation, backpropagation, and optimizer step.

TensorFlow: Simple .fit() method handles everything internally.

Loss Functions: BCELoss in PyTorch vs binary_crossentropy in Keras.

Evaluation: Using accuracy scores to measure model performance.

ğŸ” Training Process Flow

ğŸ” PyTorch vs TensorFlow â€“ Key Takeaways
Feature	PyTorch	TensorFlow/Keras
Control	âœ… High (manual loops)	âš ï¸ Lower (abstracted)
Ease of Use	âš ï¸ Steeper learning curve	âœ… Beginner-friendly
Flexibility	âœ… Customizable	âš ï¸ Requires subclassing for customization
Community	Large	Large

ğŸ“ˆ Future Improvements
Add Dropout layers to prevent overfitting.

Implement cross-validation.

Visualize loss & accuracy curves for better analysis.

Extend to multi-class datasets.

ğŸ·ï¸ License
This project is licensed under the MIT License.
Feel free to fork, modify, and use it for learning purposes.
